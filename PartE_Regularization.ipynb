{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rS_a0MxvpYul",
    "outputId": "e74ca5ec-e1ee-43ba-a1b6-04763399483e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_model =  pd.read_csv(\"train_model_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQ4SLTPxqEXt"
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g-DycdI5ph75"
   },
   "outputs": [],
   "source": [
    "train_model = train_model.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlvQPcPppkOf"
   },
   "outputs": [],
   "source": [
    "#create our X and y\n",
    "X = train_model.drop('Sales', axis=1)\n",
    "y = train_model['Sales']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "eBmKPW16pkrK",
    "outputId": "7284a460-3d78-4741-b618-87f5345b3cfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.5489182057137239\n",
      "Test score: 0.5482421567042175\n",
      "RMSE: 2567.6737275373325\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "print('Training score: {}'.format(lr_model.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(lr_model.score(X_test, y_test)))\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "print('RMSE: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "colab_type": "code",
    "id": "kka1i5xsqOSc",
    "outputId": "e74a189a-d9d4-400e-d449-779d31761025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.5877354654434662\n",
      "Test score: 0.5873613345118975\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', LinearRegression())\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print('Training score: {}'.format(pipeline.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(pipeline.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PTd8g2pdqdoq"
   },
   "source": [
    "## **L2 Regularization or Ridge Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*L2 regression ignores the least significant variables and performs the regression*\n",
    "\n",
    "*L2 regression is performed when all the variables need not be used*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "colab_type": "code",
    "id": "v6oYwtyrqWmT",
    "outputId": "0e62fc1f-f81d-4a41-ef0b-e5c6736b276e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.587735448530829\n",
      "Test Score: 0.5873613220942593\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Ridge(alpha=10, fit_intercept=True))\n",
    "]\n",
    "\n",
    "ridge_pipe = Pipeline(steps)\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Training Score: {}'.format(ridge_pipe.score(X_train, y_train)))\n",
    "print('Test Score: {}'.format(ridge_pipe.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9kUjgeRUqq9K"
   },
   "source": [
    "## **L1 Regularization or Lasso Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*L1 regularization does not ignore the least significant variables*\n",
    "\n",
    "*L1 regularization is used when all the variables must be used*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "vpcEEqf6ql_e",
    "outputId": "7aeb1787-977b-482c-8da2-c9da3faf529a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.5877274240517565\n",
      "Test score: 0.5873380284194831\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Lasso(alpha=0.3, fit_intercept=True))\n",
    "]\n",
    "\n",
    "lasso_pipe = Pipeline(steps)\n",
    "\n",
    "lasso_pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Training score: {}'.format(lasso_pipe.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(lasso_pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-regularization regression**\n",
    "\n",
    "*Dropping all the least significant variables from the train_model dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = train_model.drop(['Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceYear', 'Promo2SinceWeek', 'PromoInterval'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Creating the features \n",
    "\n",
    "features = train_model.drop('Sales', axis=1)\n",
    "target = train_model['Sales']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(704493, 9)\n",
      "(301926, 9)\n",
      "(704493,)\n",
      "(301926,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.529 0.0\n",
      "-----------------------------------------------\n",
      "Test R^2: 0.528\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "#Setting up the scaling pipeline \n",
    "\n",
    "pipeline_order = [('scaler', StandardScaler()), ('linear_reg', linear_model.LinearRegression())]\n",
    "\n",
    "Model_Pipeline = Pipeline(pipeline_order)\n",
    "\n",
    "# evaluate pipeline\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "results = cross_val_score(Model_Pipeline, X_train, y_train, cv=kfold,scoring= 'r2')\n",
    "Model_Pipeline.fit(X_train, y_train)\n",
    "preds_train = Model_Pipeline.predict(X_train)\n",
    "preds = Model_Pipeline.predict(X_test)\n",
    "print(\"Train R^2:\",round(results.mean(),3), round(results.std(),3))\n",
    "#print(\"Train AIC, BIC :\",round(calAIC(y_train,preds_train,len(X_train.columns)),3),\",\", round(calBIC(y_train,preds_train,len(X_train.columns))))\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"Test R^2:\",round(r2_score(y_test, preds),3))\n",
    "#print(\"Test AIC, BIC :\",round(calAIC(y_test,preds,len(X_test.columns)),3),\",\", round(calBIC(y_test,preds,len(X_test.columns))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The train and test values are same in regularization regression and non-regularization regression.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **The accuracy of the data is 54% for linear regression. To increase the accuracy I used random forest algorithm. After applying random forest, the accuracy has increased to . The accuracy of the data is 74% for logistic regression. We found multicolinearity in one variable i.e, \"Promo2\". There is no difference between regularization and non-regularization regression.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7GwhN_eHqvMX"
   },
   "source": [
    "## Contributions Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*By own : 80%*\n",
    "\n",
    "*External Source : 20%*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/elenapetrova/time-series-analysis-and-forecasts-with-prophet\n",
    "\n",
    "https://www.statisticssolutions.com/assumptions-of-logistic-regression/\n",
    "\n",
    "https://www.statisticssolutions.com/assumptions-of-linear-regression/\n",
    "    \n",
    "https://www.python-course.eu/confusion_matrix.php\n",
    "    \n",
    "https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c\n",
    "    \n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n",
    "    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "    \n",
    "https://towardsdatascience.com/linear-regression-using-python-ce21aa90ade6\n",
    "    \n",
    "https://www.statisticssolutions.com/what-is-logistic-regression/\n",
    "    \n",
    "https://www.medcalc.org/manual/logistic_regression.php\n",
    "    \n",
    "https://www.statisticssolutions.com/multicollinearity/\n",
    "\n",
    "https://newonlinecourses.science.psu.edu/stat501/node/343/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 Harshitha Sanikommu\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "PartE: Regularization",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
